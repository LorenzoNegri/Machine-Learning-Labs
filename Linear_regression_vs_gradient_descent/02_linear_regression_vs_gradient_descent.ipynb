{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression versus Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results\n",
      "Intercept 30.098860539622496 Coefficient [-0.06822828]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"mtcars.csv\")                       \n",
    "                        \n",
    "X = np.array(train_data[\"hp\"])  ; y = np.array(train_data[\"mpg\"]) \n",
    "X = X.reshape(32,1); y = y.reshape(32,1)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression(fit_intercept = True) \n",
    " \n",
    "model.fit(X,y)       \n",
    "print (\"Linear Regression Results\")        \n",
    "print (\"Intercept\",model.intercept_[0] ,\"Coefficient\",model.coef_[0])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will use the gradient_descent module created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_descent import myDescent as gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged, iterations:  1144449\n",
      "Gradient Descent Results\n",
      "Intercept = [30.02495128] Coefficient = [-0.06781243]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    Inter, Coeff = gd(x = X,y = y,learn_rate=0.00003 ,conv_threshold=1e-8, batch_size=32,max_iter=1500000)\n",
    "    print (\"Gradient Descent Results\")\n",
    "    print (('Intercept = %s Coefficient = %s') %(Inter, Coeff)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When shall we use gradient descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mainly it is used for linear regression when the computational complexity is high: it's computationally cheaper (faster) to find the solution using the gradient descent in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also the way it allows for parallelization; distributing the calculations across multiple processors or machines. The classic linear algebra solution can also be parallelized but it's more complicated and still expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, there are versions of gradient descent when you keep only a piece of your data in memory, lowering the requirements for computer memory. Overall, for extra large problems it's more efficient than linear algebra solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
