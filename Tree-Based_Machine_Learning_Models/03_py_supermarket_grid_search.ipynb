{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Problem with Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find out if a particular client of the supermarket will buy a selected product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out if a particular client of the supermarket will buy a selected product based on client type and what he has in the basket. The file available is a csv with a few clients habits and a basket record of products from where we can predict if a product will be in the basket or not. To solve this problem I'll use a machine learning **Decision Tree CLassifier** and a method called ***grid search*** to tune the hyperparameters of the model in order to find the best combination for determining the best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search on Decision Trees\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_01</th>\n",
       "      <th>type_02</th>\n",
       "      <th>$_ratio</th>\n",
       "      <th>classic_out</th>\n",
       "      <th>UHIYL</th>\n",
       "      <th>9YZKX</th>\n",
       "      <th>15U8X</th>\n",
       "      <th>7DUSJ</th>\n",
       "      <th>C6EH6</th>\n",
       "      <th>9VBFU</th>\n",
       "      <th>...</th>\n",
       "      <th>7D1EV</th>\n",
       "      <th>5ZOSV</th>\n",
       "      <th>TGZDY</th>\n",
       "      <th>2B1M7</th>\n",
       "      <th>V1G4A</th>\n",
       "      <th>QPIAJ</th>\n",
       "      <th>MSA6G</th>\n",
       "      <th>4UELQ</th>\n",
       "      <th>Y56GT</th>\n",
       "      <th>D3XJV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>5.431005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>468</td>\n",
       "      <td>44.151799</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>230</td>\n",
       "      <td>36.946190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>41.689841</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>42.219841</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3274</td>\n",
       "      <td>170</td>\n",
       "      <td>94</td>\n",
       "      <td>2.955397</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3275</td>\n",
       "      <td>101</td>\n",
       "      <td>140</td>\n",
       "      <td>8.133862</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3276</td>\n",
       "      <td>23</td>\n",
       "      <td>120</td>\n",
       "      <td>27.944762</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3277</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3278</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>5.931005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3279 rows × 1559 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type_01  type_02    $_ratio  classic_out  UHIYL  9YZKX  15U8X  7DUSJ  \\\n",
       "0         125      125   5.431005            1      0      0      0      0   \n",
       "1          57      468  44.151799            1      0      0      0      0   \n",
       "2          33      230  36.946190            1      0      0      0      0   \n",
       "3          60      468  41.689841            1      0      0      0      0   \n",
       "4          60      468  42.219841            1      0      0      0      0   \n",
       "...       ...      ...        ...          ...    ...    ...    ...    ...   \n",
       "3274      170       94   2.955397            0      0      0      0      0   \n",
       "3275      101      140   8.133862            1      0      0      0      0   \n",
       "3276       23      120  27.944762            1      0      0      0      0   \n",
       "3277       -1       -1  -1.000000            1      0      0      0      0   \n",
       "3278       40       40   5.931005            1      0      0      0      0   \n",
       "\n",
       "      C6EH6  9VBFU  ...  7D1EV  5ZOSV  TGZDY  2B1M7  V1G4A  QPIAJ  MSA6G  \\\n",
       "0         0      0  ...      0      0      0      0      0      0      0   \n",
       "1         0      0  ...      0      0      0      0      0      0      0   \n",
       "2         0      0  ...      0      0      0      0      0      0      0   \n",
       "3         0      0  ...      0      0      0      0      0      0      0   \n",
       "4         0      0  ...      0      0      0      0      0      0      0   \n",
       "...     ...    ...  ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3274      0      0  ...      0      0      0      0      0      0      0   \n",
       "3275      0      0  ...      0      0      0      0      0      0      0   \n",
       "3276      0      0  ...      0      0      0      0      0      0      0   \n",
       "3277      0      0  ...      0      0      0      0      0      0      0   \n",
       "3278      0      0  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "      4UELQ  Y56GT  D3XJV  \n",
       "0         0      0      1  \n",
       "1         0      0      1  \n",
       "2         0      0      1  \n",
       "3         0      0      1  \n",
       "4         0      0      1  \n",
       "...     ...    ...    ...  \n",
       "3274      0      0      0  \n",
       "3275      0      0      0  \n",
       "3276      0      0      0  \n",
       "3277      0      0      0  \n",
       "3278      0      0      0  \n",
       "\n",
       "[3279 rows x 1559 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = pd.read_csv(\"cs_buy_data.csv\")\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the csv file we have 3278 recorded clients samples of their buying habits with 1559 features from few client parameters and all the products with 1 or 0 telling us if there are in the client basket or not at the checkout:\n",
    " - **type_01**: a private categorical parameter assigned to a client\n",
    " - **type_02**: another private categorical parameter assigned to a client\n",
    " - **\\$_ratio**: buying average ratio, a parameter for expense measure of the client\n",
    " - **classic_out**: whether or not the client uses a standard checkout procedure\n",
    " - **UHIYL ...**:  the rest of feauters are the IDs of products when 1=bought toghether with the label product\n",
    " - **D3XJV**: the label ID product we want to predict when it will be in the basket or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " summary Label product stats: \n",
      "\n",
      " 0    2820\n",
      "1     459\n",
      "Name: D3XJV, dtype: int64\n",
      "\n",
      " summary $_ratio stats: \n",
      "\n",
      " count    3279.000000\n",
      "mean       15.046839\n",
      "std        28.945317\n",
      "min        -1.000000\n",
      "25%        -1.000000\n",
      "50%         6.800423\n",
      "75%        21.329021\n",
      "max       318.430318\n",
      "Name: $_ratio, dtype: float64\n",
      "\n",
      " summary category type: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_01</th>\n",
       "      <th>type_02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>3279</td>\n",
       "      <td>3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unique</td>\n",
       "      <td>221</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>top</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>freq</td>\n",
       "      <td>903</td>\n",
       "      <td>901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type_01  type_02\n",
       "count      3279     3279\n",
       "unique      221      278\n",
       "top          -1       -1\n",
       "freq        903      901"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print summary statistics for some features\n",
    "stats = dat['D3XJV'].value_counts()\n",
    "print(\"\\n summary Label product stats: \\n\\n\", stats)\n",
    "stats = dat.iloc[:,2]\n",
    "print(\"\\n summary $_ratio stats: \\n\\n\", stats.describe())\n",
    "stats = dat.iloc[:,:2].astype('object')\n",
    "print(\"\\n summary category type: \\n\")\n",
    "stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product label we need to predict has been added to the market basket by 459 clients and 2820 have not added it. The spending ammount ratio tells us that the mean ratio is 15.04\\\\$ and the maximum 318.43\\\\$. We see that -1 is NA (not available value for that client) we found it on type_01 and type_02 as well. Clients type_01 and type_02 parameters have 221 and 278 unique values rrespectively. We have a lot of NAs with more o less of 900 missing over 3279 of total samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " summary $_ratio stats: \n",
      "\n",
      " count     3279.0\n",
      "unique    1955.0\n",
      "top         -1.0\n",
      "freq       910.0\n",
      "Name: $_ratio, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# checking missing values on $_ratio\n",
    "stats = dat.iloc[:,2].astype('object')\n",
    "print(\"\\n summary $_ratio stats: \\n\\n\", stats.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we leave the NAs as they are for the moment. And just to be sure I'll check if there are other numbers in the products basket binary feautures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dat.drop(['type_01', 'type_02', '$_ratio'], axis=1).to_numpy()\n",
    "X = X.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count missing or wrong values \n",
    "def missing(array):\n",
    "    nas = 0\n",
    "    nas = [0 if x !=0 or x !=1 else nas +1 for x in X]\n",
    "    tot = sum(nas)\n",
    "    return(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  values are missing or are not binary\n"
     ]
    }
   ],
   "source": [
    "# check for missing or other values not 0 and 1\n",
    "print(missing(X), \" values are missing or are not binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I know drop the label column and prepare the independent variables X and the dependent to predict y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dat.drop('D3XJV', axis=1).to_numpy()\n",
    "y = dat['D3XJV'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn does not have a function to divide the data into three parts. So, I'm going to call that function twice, once to split data into two sets: _a._ training; and _b._ validation and test combined. Then, we call the function once more to split that second set into distinct validation and test sets. We chose to reserve 0.4 (or 40%) of our data for validation and test and 1 - 0.4 = 0.6 or 60% of our data for training. From the 40% left for validation and test, we are going to use 0.5 or 50% of it (which make sit 20% of the total amount of data) for validation and the other 50% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and split training and test sets\n",
    "(X_train, X_vt, y_train, y_vt) = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "(X_validation, X_test, y_validation, y_test) = train_test_split(X_vt, y_vt, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search is implemented next using a decision tree classifier for classification purposes. The tuning parameters will be depth of the tree, the minimum number of observations in terminal node, and the minimum number of observations required to perform the node split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to create combinations of variables for the grid search:\n",
    "pipeline = Pipeline([\n",
    "    ('clf', DecisionTreeClassifier(criterion='entropy'))\n",
    "])\n",
    "\n",
    "# Combos to explore given parameters in Python dict. format:\n",
    "parameters = {\n",
    "    'clf__max_depth': (50,100,150),\n",
    "    'clf__min_samples_split': (2, 3),\n",
    "    'clf__min_samples_leaf': (1, 2, 3)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the `n_jobs` field is for selecting the numbers of cores in the computer; -1 means it uses all the cores available. The scoring methodology choosen is accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:   19.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('clf',\n",
       "                                        DecisionTreeClassifier(class_weight=None,\n",
       "                                                               criterion='entropy',\n",
       "                                                               max_depth=None,\n",
       "                                                               max_features=None,\n",
       "                                                               max_leaf_nodes=None,\n",
       "                                                               min_impurity_decrease=0.0,\n",
       "                                                               min_impurity_split=None,\n",
       "                                                               min_samples_leaf=1,\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               presort=False,\n",
       "                                                               random_state=None,\n",
       "                                                               splitter='best'))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': (50, 100, 150),\n",
       "                         'clf__min_samples_leaf': (1, 2, 3),\n",
       "                         'clf__min_samples_split': (2, 3)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to predict the label y using the best parameters of grid search on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Grid Search Best score: \n",
      " 0.9679715302491103\n",
      "\n",
      " Best parameters set: \n",
      "\n",
      "\tclf__max_depth: 100\n",
      "\tclf__min_samples_leaf: 1\n",
      "\tclf__min_samples_split: 3\n",
      "\n",
      " Confusion Matrix on validation data \n",
      " [[543  12]\n",
      " [ 16  85]]\n",
      "\n",
      " Validation Accuracy \n",
      " 0.9573170731707317\n",
      "\n",
      "Precision Recall f1 table \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       555\n",
      "           1       0.88      0.84      0.86       101\n",
      "\n",
      "    accuracy                           0.96       656\n",
      "   macro avg       0.92      0.91      0.92       656\n",
      "weighted avg       0.96      0.96      0.96       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('\\n Grid Search Best score: \\n', grid_search.best_score_)\n",
    "print ('\\n Best parameters set: \\n')\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print ('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "print (\"\\n Confusion Matrix on validation data \\n\",confusion_matrix(y_validation,y_pred))\n",
    "print (\"\\n Validation Accuracy \\n\",accuracy_score(y_validation,y_pred))\n",
    "print (\"\\nPrecision Recall f1 table \\n\",classification_report(y_validation, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **confusion matrix** on validation data we can see that **550** are the ***True Positives*** (predicted as added to the basket and actually added by the client), **12** are the ***False Negatives*** (predicted as not added but actually added to the basket by the client), **16** are the ***False Positives*** (predicted as added to the basket but actually not added by the client) and **85** are the ***True Negatives*** (predicted as not added to the basket and actually not added by the client). The total **Validation Accuracy** is **96.7%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Confusion Matrix on test data \n",
      " [[557  10]\n",
      " [ 10  79]]\n",
      "\n",
      " Test Accuracy \n",
      " 0.9695121951219512\n",
      "\n",
      "Precision Recall f1 table \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       567\n",
      "           1       0.89      0.89      0.89        89\n",
      "\n",
      "    accuracy                           0.97       656\n",
      "   macro avg       0.94      0.94      0.94       656\n",
      "weighted avg       0.97      0.97      0.97       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "print (\"\\n Confusion Matrix on test data \\n\",confusion_matrix(y_test,y_pred))\n",
    "print (\"\\n Test Accuracy \\n\",accuracy_score(y_test,y_pred))\n",
    "print (\"\\nPrecision Recall f1 table \\n\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally with the **Test Accuracy** of Test Data we score **96.9%**. The result is not overfitted and similiar to the others validation and train, so it looks like a rubust model. We can manage the missing data and see if we can get better results, but the model could go in production and can be tuned later on. To have more confidence it can be made a ***cross-validation*** analysis to ensure the robustness of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
